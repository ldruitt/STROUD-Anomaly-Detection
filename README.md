# STROUD-Anomaly-Detection
Implement the STROUD (strangeness-based outlier detection) algorithm using LOF (local outlier factor) as strangeness

Approach: For this project I was to implement the STROUD (strangeness-based outlier detection) algorithm using LOF (local outlier factor) as strangeness. Given different directories of normal signals and anomalous signals I was able to create strangeness lists and a probability list to represent the different LOF values’ probability of being an anomaly. First I got all the signals from all the directories on my device (after removing the empty files) and compiled them into separate lists using numpy’s loadtxt function. I took a random sample of 30 signals from A B C and D and shuffled them to be randomly distributed in order to create a normal base of 120 signals with 20000 features. I used the normal base and ran each signal through Numpy’s fft and this became my training data. I used the training set to calculate the LOF for each point in respect to the other training points. My method for calculating LOF was to create a NearestNeighbors classifier from scikit and fit it with my training data. For every point in my training data (called q) I used scikits kneighbors function on q for k points which gave me the indices of the nearest neighbors and the distances they had from the point in two separate arrays. I chose 18 as my k because I got the best average results across every base I tried. The distances are each a reachability distance of my min-points (set of p minpoints) which I can then use to get my local reachability distance (LRD) of q with: LRD(q) = 1/k *  reachability distances(q, p’s) My next step was to get LRD of each p in the set of min-points by getting the kneighbors output with reachability distances for each of the points and computing the LRD in the same way as q, and then adding this LRD number to a total sum of LRD’s for all p such that: LRD(p) = 1/k *  reachability distances(p, nearest neighbors) LRD(p)sum =  LRD(p’s) I can now get the LOF for q with the sum of LRD of p and the sum of LRD of q with: LOF(q) = 1/k * (LRD(p)sum/LRD(q)) I add this LOF value to the strangeness training list and then sort the final list in ascending order. Next I was able to create a test set by taking 30 random signals from  A, B, C, D, and M and shuffled the signals to retain the randomness of the distribution of 150 signals with 20000 features. After this step I go through the list to find where the anomalies exist in the list of signals and keep track of these indices. I run each of these signals through numpy’s fft to create a test data set. I use the test data set to compute LOF and test strangeness list much in the same way I did the training strangeness however, I fit my NearestNeighbors classifier to the training data in order to compare the points in the test set to the ones in the training set. Once I form the strangeness testing list I do not sort it but instead preserve the order.  I then took the measures in my test strangeness list and found its place on the strangeness training list. For each element of the strangeness test list I appended the element to the strangeness training list then used numpy’s sum function to count the number of points in the list that were greater than or equal to the point and called this number b. I then divided b by the size of the training strangeness list plus one and that became the p-value of that test point such that: 
p = b/N+1 I removed the current measure of the strangeness test list from the training set and continue this process for all the strangeness test points and create the list of p values.  I created a list of anomaly labels using the indices of all the M signals and created an array of ones placing zeros where the anomalies exist. I then got my AUC score using scikits roc_auc_score on the list of p values against the anomaly labels. For the given set of test points I did all of this but instead of my test set I used the 499 signals from TestTW and wrote the list of p-values to an output file called output.txt. 
 
Methodology: I chose samples of 30 of each directory of signals because out of around 100 samples in each directory I felt this would be the best way to get a normal base for test and train with good distribution from each directory.   When calculating my FFT I tried a single sided fft by multiplying the signals frequencies by two and removing the second half of the frequencies such that: G​AA​(i)=S​AA​(i), i = 0 (DC) G​AA​(i)=2xS​AA​(i), i = 1 to N/2-1 However I found that this did not seem to change the efficiency and minorly decreased my accuracy so I decided to continue with the double sided FFT instead. I modeled my LRD and LOF computation off of the slides recommendations and this seemed to work fine for me, my strangeness gave me values in the expected range. For my choice of k I created random bases and tested different k’s a number of times and got the average auc score for each k. The best average score I got was 0.970694 for k = 18 which I chose as my final k. 
